# Performance Comparison of C and x86-64 Assembly Functions

This project benchmarks and analyzes the performance of matrix operations implemented in both C and x86-64 assembly. Below, you'll find detailed execution time comparisons and a correctness check to validate the outputs.

## Execution Time and Analysis

### 10x10 Matrix
- **Assembly Function Time (Avg):** 0.000356 ms  
- **C Function Time (Avg):** 0.000413 ms  
- **Total Time (Avg):** 0.00077 ms  

The performance for small matrices is nearly identical, with assembly having a slight edge due to reduced function overhead. The difference is negligible at this scale.

### 100x100 Matrix
- **Assembly Function Time (Avg):** 0.03987 ms  
- **C Function Time (Avg):** 0.03664 ms  
- **Total Time (Avg):** 0.07651 ms  

For mid-sized matrices, C functions perform slightly better, likely because of compiler optimizations. However, the difference is minimal, and assembly remains competitive.

### 1000x1000 Matrix
- **Assembly Function Time (Avg):** 2.87488 ms  
- **C Function Time (Avg):** 3.29707 ms  
- **Total Time (Avg):** 6.17195 ms  

As matrix size grows, assembly functions outperform C significantly, demonstrating their efficiency for larger computational loads.

### Summary
Assembly functions show clear performance benefits for large datasets, attributed to their low-level optimizations. However, C functions benefit from high-level compiler optimizations and are often easier to maintain.

## Correctness Check (C)

Below is a screenshot of the program output validating the correctness of results generated by the C implementation:

![Correctness Check](path_to_your_screenshot.png)

The correctness of the outputs was verified by comparing the results of both C and assembly functions against known correct values for various matrix sizes.

## Key Takeaways
1. **Small Matrices:** Minimal performance difference between C and assembly.  
2. **Mid-Sized Matrices:** C functions leverage compiler optimizations for competitive performance.  
3. **Large Matrices:** Assembly outperforms due to lower-level optimizations and reduced overhead.  

## Future Improvements
- Explore vectorized operations (e.g., SIMD instructions) for further optimization in assembly.
- Investigate compiler flags to enhance C performance for large matrices.

---